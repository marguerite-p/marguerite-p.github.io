---
title: Robotique, les dangers de l'empathie artificielle
category: science
meta-description: Peut-on ressentir de l'empathie envers les robots ? Dangers psychologiques autour de l'empathie artificielle...

preview_image: /assets/images/science/empathie-artificielle/empathie-artificielle-preview.jpg
hero_image: /assets/images/science/empathie-artificielle/empathie-artificielle-hero.jpg
share_image : /assets/images/science/empathie-artificielle/empathie-artificielle-share.jpg


tags:
- robotique
- robots
- homme-machine
- empathie artificielle
- intelligence artificielle

date: 2018-01-01
---

<h2 class="is-chapo">Toute relation interpersonnelle est fondée sur l’empathie. Avec les progrès en intelligence artificielle, la question de nos relations avec des robots qui arrivent de mieux en mieux à imiter le comportement humain est fréquemment posée dans les films de science-fiction: Her, Ex-Machina, Real Humans... Mais qu’en est-il dans la vraie vie ?</h2> 

## Empathie envers les robots : deux études concluantes

Deux études récentes prouvent que nous serions capables de **ressentir de l’empathie envers les robots**, une empathie semblable à celle que l'on éprouve envers nos semblables. La première étude de l’Université de Duisbourg-Essen en Allemagne[1] a observé des sujets humains face à une vidéo où un petit robot dinosaure nommé Pléo était traité successivement de façon brutale ou affectueuse. Dans la première partie de l’expérience, les chercheurs ont mesuré la conductance de la peau (comment la peau conduit l’électricité) des 40 participants. Lorsqu’ils ont visionné des vidéos violentes, les mesures ont révélé que la conductance de leur peau augmentait (nous transpirons plus quand nous ressentons des émotions fortes), même s'ils affirmaient ne pas avoir été choqués. 

<iframe width="560" height="315" src="https://www.youtube.com/embed/wAVtkh0mL20" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

La seconde partie de l’expérience mesurait par technique IRM l’activité cérébrale face à des images de violence à l’égard d’humains, de robots, puis d’objets quelconques. Il s’avère que l’activité neuronale dans les régions du système limbique est identique lorsque les participants sont confrontés à des vidéos de **violence à l’égard d’humains et de robots**. Une autre étude japonaise [2] révèle que les mêmes zones du cerveau s’activent lorsque l’on voit **un humain ou un robot dans une situation de souffrance** (étude de l’activité cérébrale par électroencéphalographie). 

![test empathie artificielle main robot et humain](/assets/images/science/empathie-artificielle/empathie-artificielle-1.jpg)

## Des funérailles pour les robots militaires

Les **sentiments que nous projetons dans les robots** ne sont pas sans risques. **Peter Singer**, un chercheur en sciences politiques américain, a mis en évidence que **des soldats sont prêts à mettre leur vie en danger pour sauver leurs robots démineurs** [3]. Ces soldats américains avouent ressentir de la peine et de la colère lorsque leurs robots démineurs sont détruits. **Certains vont même jusqu’à leur organiser des funérailles et leur décerner des médailles de mérite lors de cérémonies**. Les soldats vouent un grand sentiment de reconnaissance à ces robots qui ont combattu à leurs côtés et maintes fois sauvé leurs vies. 

J’ai eu la chance d’entrer en contact avec **Julie Carpenter**, une chercheuse américaine qui travaille sur les relations humains-robot, ainsi qu’un colonel retraité avec qui j’ai échangé quelques mails. Julie Carpenter m’a expliqué que **les militaires perçoivent davantage leurs robots démineurs comme des animaux de compagnie ou des amis**, certains leur donnant même un nom, parfois celui de leur femme ou de leur copine. 

Selon une anecdote désormais mythique, un soldat en pleurs aurait ramené son robot surnommé *Scooby-Doo* en réparation. Malgré le fait qu’on lui ait assuré qu’il obtiendrait un nouveau robot, le soldat serait resté inconsolable. Il ne voulait que «Scooby-Doo».

## Le robot : un ersatz d’humain ?

Les psychologues, eux, s’inquiètent que les robots viennent abîmer nos relations inter-humaines. En 1995, la chercheuse **Rosalind Picard** du MIT publiait un article sur l’« **informatique affective** ». Elle y supposait que les robots devaient être capables de « ressentir » et d’ « exprimer » pour mieux nous servir. **Faut-il réellement doter les robots d’une « empathie artificielle. » ?** 

Aujourd’hui, des robots sont déjà en capacité d’analyser nos émotions et de transmettre un semblant d’émotion en retour. C’est le cas des robots PARO et Nao, qui grâce à des capteurs peuvent détecter les micro-expressions et l’intonation de la voix de leur interlocuteur, et de transmettre une réponse émotionnelle appropriée. Pour **Serge Tisseron**, psychiatre et psychanalyste, auteur de *Le jour où mon robot m’aimera* [4] : 

> « un des risques est que certains humains développent une empathie trop grande à l'égard de ces robots "sensibles", qu'ils se mettent en danger pour protéger ces machines ou qu'ils se laissent manipuler par elles. [5] » 

Il s'inquiète qu’à terme on finisse par préférer la compagnie robotique à la compagnie humaine et qu'on attende des autres qu'ils se comportent comme des robots : **« serviables, gentils et sans ego »**. 

Une chose est sûre: **Les robots sont des objets animés hors du commun qui modifient notre relation aux objets**. C’est la première fois qu’on se permet de les aimer, qu’on y développe des relations de dépendance. Pour Serge Tisseron le titre de son livre se fonde sur un mensonge : " Non, jamais mon robot ne m'aimera, et s’il me dit qu’il m’aime, ce ne sera qu’illusion". 

Il s’oppose à l’idée de Kate Darling de **protéger les robots de la maltraitance par la loi**, car reconnaître que les robots souffrent, c’est nous plonger dans l’illusion. Serge Tisseron milite pour que les futurs possesseurs de robots puissent les monter et les démonter eux-mêmes : « C’est la meilleure façon de rester conscients qu’il s’agit de machines ». 

## Aimer son robot ?

![Bender Futurama aimer son robot](/assets/images/science/empathie-artificielle/empathie-artificielle-1.jpg)
Le robot Bender dans la série Futurama

Dans la série suédoise **Real Humans**, les **relations sexuelles avec son robot** ou un robot de prostitution sont socialement acceptées, ce qui a interpellé de nombreux téléspectateurs. Pourtant, certains voient en les robots l’avenir des sex toys et des poupées gonflables. Dans son livre *Love and Sex with Robots* (2007), le chercheur britannique **David Levy** craint que dans cinquante ans **la robophilie** devienne la norme. Pour la maître de conférences en psychologie **Helen Driscoll**, la **sex tech** (technologie du sexe) est vouée à se développer rapidement : 

> « la réalité augmentée deviendra plus réaliste et immersive et sera capable d’imiter et même d’améliorer l’expérience sexuelle avec un partenaire humain, il est envisageable que certains préfèrent cette alternative à un partenaire humain plus imparfait [6].” 

Ainsi des mots comme sextech, lovetech, lovotics font progressivement leur apparition dans le jargon robotique...


Si certains psychologues craignent que le robot devienne un substitut aux relations humaines, d’autres pensent qu’il peut au contraire devenir un catalyseur de relations sociales. Là est l’idée de chercheurs en **robotique sociale** comme **Véronique Aubergé** du LIG de Grenoble, pour qui [le robot peut se fondre dans le tissu social](https://www.echosciences-grenoble.fr/communautes/monstrueux/articles/rencontre-avec-l-equipe-du-lig-de-la-robotique-de-service-a-la-robotique-sociale){:target="_blank"} sans se substituer à l’humain. 

## Alors, prêts à vivre avec les robots?

<div class="has-text-right">Article initalement publié sur <a href="https://www.echosciences-grenoble.fr/communautes/monstrueux/articles/les-dangers-de-l-empathie-artificielle#_ftn1" target="_blank">Echosciences</a> le 16/05/16</div>

#### Sources :

[1] ROSENTHAL VON DER PÜTTEN A.., HOFFMAN A., SOBIERAJ S., EIMLER S., ”An experimental study on emotional reactions towards a robot”, International Journal of Social Robotics, January 2013
[2] SUZUJI Y., GALLI L., IKEDA A., ITAKURA S., KITAZAKI M., ”Measuring empathy for human and robot hand pain using electroencephalography”, Scientific Reports, November 2015
[3] . SINGER P.W., Wired For War: The Robotics Revolution and Conflict in the 21st Century, Penguin, 2009)
[4] TISSERON S., Le jour où mon robot m’aimera, vers l’empathie artificielle, Albin Michel, septembre 2015
[5] HENNO J., « Les robots face au défi de l’empathie », Lesechos.fr, 08/09
http://www.lesechos.fr/idees-debats/sciences-prospective/021304845082-les-robots-face-au-defi-de-lempathie-1153265.php
[6] Ibid. HENNO J., « Les robots face au défi de l’empathie »


